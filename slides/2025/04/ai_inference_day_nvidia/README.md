## AI Inference Day with NVIDIA


## Slides

| S. No | Name of Talk | Speaker Name | Slides URL |
|-------|--------------|--------------|------------|
| 1 |  NVIDIA Inference Stack Demystified  | Amit Kumar, NVIDIA | [Download]() |
| 2 |  LLM Inference Optimization and Serving using TensorRT-LLM and NVIDIA Dynamo | Utkarsh Uppal, NVIDIA | [Download]() |
| 3 |  Bridging Data & AI: How Cloudera and NVIDIA Drive the Future of Intelligent Enterprises | Manick Mehra, Anukrati Saxena & Navin Agrawal, Cloudera Team | [Download](https://github.com/collabnix/dockerbangalore/blob/4d91fd6448fca1db9f41d221aaf9d23b5aa70f61/slides/2025/04/ai_inference_day_nvidia/AI%20Inference%20Day-Cloudera%20(1).pdf) |
| 4 |  GPU-Accelerated AI Inference for Local LLM Development with Docker Model Runner | Ajeet Singh Raina, DevRel, Docker | [Download](https://github.com/collabnix/dockerbangalore/blob/master/slides/2025/04/AI%20Inference%20Meetup%20-%20Model%20Runner.pdf) |
| 5 |  AI Inference for enhanced performance and accessibility with TensorRT-LLM | Sarvam.AI Team | [Download]() |
| 6 |  Securing LLM Apps with NVIDIA Nemo Guardrails | Jayita Bhattacharya, Deliotte | [Download]() |
| 7 |  Fine-Tuning LLMs Locally with NIM and NVIDIA NIM Microservices: A Live Demo | Manjunath Janardhan MSG Global Solutions | [Download](https://github.com/collabnix/dockerbangalore/blob/master/slides/2025/04/NVIDIA.pptx) |





