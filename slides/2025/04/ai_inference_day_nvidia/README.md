## AI Inference Day with NVIDIA


## Slides

| S. No | Name of Talk | Speaker Name | Slides URL |
|-------|--------------|--------------|------------|
| 1 |  NVIDIA Inference Stack Demystified  | Amit Kumar, NVIDIA | [Download]() |
| 2 |  LLM Inference Optimization and Serving using TensorRT-LLM and NVIDIA Dynamo | Utkarsh Uppal, NVIDIA | [Download]() |
| 3 |  Bridging Data & AI: How Cloudera and NVIDIA Drive the Future of Intelligent Enterprises | Manick Mehra, Anukrati Saxena & Navin Agrawal, Cloudera Team | [Download]() |
| 4 |  GPU-Accelerated AI Inference for Local LLM Development with Docker Model Runner | Ajeet Singh Raina, DevRel, Docker | [Download]() |
| 5 |  AI Inference for enhanced performance and accessibility with TensorRT-LLM | Sarvam.AI Team | [Download]() |
| 6 |  Securing LLM Apps with NVIDIA Nemo Guardrails | Jayita Bhattacharya, Deliotte | [Download]() |
| 7 |  Fine-Tuning LLMs Locally with NIM and NVIDIA NIM Microservices: A Live Demo | Manjunath Janardhan GE Healthcare | [Download]() |





